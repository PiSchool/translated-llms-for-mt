{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvXCUyTYdCJw",
        "outputId": "f60c2c30-cdab-4ecf-b6e2-602acf91d31d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sRmmiJWFuAh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip install datasets\n",
        "!pip install tensorRT\n",
        "!pip install unbabel-comet\n",
        "!pip install wandb\n",
        "!pip install bitsandbytes\n",
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3VsBDUdbUdY",
        "outputId": "c02fc35d-4cbc-45e3-e40d-c404604b86cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find: ‘/proc/54/task/54/net’: Invalid argument\n",
            "find: ‘/proc/54/net’: Invalid argument\n",
            "/usr/local/lib/python3.9/dist-packages/tensorrt/libnvinfer.so.8\n",
            "/usr/local/lib/python3.9/dist-packages/tensorrt/libnvinfer_plugin.so.8\n",
            "/usr/local/lib/python3.9/dist-packages/tensorrt/libnvinfer_builder_resource.so.8.6.0\n"
          ]
        }
      ],
      "source": [
        "!sudo find / -name libnvinfer*.so* -print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvQTri_7LeYg",
        "outputId": "e6910fd5-2e87-45c2-8f96-f142b9d28956"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.chrf_score import sentence_chrf, corpus_chrf\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from comet import download_model, load_from_checkpoint\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration, BloomModel, MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType, prepare_model_for_int8_training\n",
        "from datasets import load_dataset, DatasetDict\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
        "\n",
        "import logging\n",
        "logging.disable(logging.CRITICAL)\n",
        "\n",
        "import wandb\n",
        "\n",
        "from pytorch_lightning import (\n",
        "    LightningDataModule, LightningModule, \n",
        "    Trainer, seed_everything)\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9erzsvBcvzC"
      },
      "outputs": [],
      "source": [
        "m = \"t5\" # \"bloom\" \"t5\" ---- in future maybe also \"mbart\" \"nllb\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvnIsEAyJwQD"
      },
      "outputs": [],
      "source": [
        "method = \"peft\" # \"peft\" or \"normal\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayVsaD_iFRcR"
      },
      "source": [
        "# Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSLRa1DbBNQa"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "\n",
        "    def __init__(self, model_name='Unbabel/wmt22-comet-da'):\n",
        "\n",
        "        self.COMET_model_path = download_model(model_name, saving_directory='./models/')\n",
        "        self.COMET_sytem_score = 0\n",
        "\n",
        "    def calculate_sentence_bleu(self, dataframe):\n",
        "        \"\"\"\n",
        "        Calculating the sentence BLEU score for each translation.\n",
        "        \"\"\"\n",
        "        dataframe['BLEU2'] = 0\n",
        "        dataframe['BLEU3'] = 0\n",
        "        dataframe['BLEU4'] = 0\n",
        "        smoothie = SmoothingFunction().method4\n",
        "        weights = [\n",
        "            (1./2., 1./2.),\n",
        "            (1./3., 1./3., 1./3.),\n",
        "            (1./4., 1./4., 1./4., 1./4.)\n",
        "            ]        \n",
        "        for i, r in dataframe.iterrows():   \n",
        "            bleu_scores = sentence_bleu([word_tokenize(str(r['target']))], word_tokenize(str(r['translation']))\n",
        "                                       , weights, smoothing_function=smoothie)\n",
        "            \n",
        "            dataframe.at[i, 'BLEU2'] = bleu_scores[0]\n",
        "            dataframe.at[i, 'BLEU3'] = bleu_scores[1]\n",
        "            dataframe.at[i, 'BLEU4'] = bleu_scores[2]\n",
        "\n",
        "        return dataframe\n",
        "\n",
        "    def calculate_sentence_chrf(self, dataframe):\n",
        "        \"\"\"\n",
        "        Calculating the sentence chrf score for each translation.\n",
        "        \"\"\"\n",
        "        dataframe['chrf'] = 0\n",
        "        for i, r in dataframe.iterrows():\n",
        "            chrf_score = sentence_chrf((str(r['target'])), str(r['translation']))\n",
        "            dataframe.at[i, 'chrf'] = chrf_score\n",
        "\n",
        "        return dataframe\n",
        "\n",
        "    def calculate_COMET(self, dataframe, batch_size=16, gpu_numbers=1):\n",
        "        \"\"\"\n",
        "        Calculating the COMET score for each translation and also COMET sytem_score for entire translations.\n",
        "        Args\n",
        "            batch_size (:obj: 'int'): batch_size\n",
        "            gpu_numbers (:obj: 'int'): Number of GPUs\n",
        "        Returns\n",
        "            dataframe with added COMET score\n",
        "        \"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_numbers = gpu_numbers\n",
        "        else:\n",
        "            gpu_numbers = 0\n",
        "\n",
        "        model = load_from_checkpoint(self.COMET_model_path)\n",
        "        data_list = []\n",
        "        for i, r in dataframe.iterrows():\n",
        "            data = {\n",
        "                'src': str(r['source']),\n",
        "                'mt': str(r['translation']),\n",
        "                'ref': str(r['target'])\n",
        "                }\n",
        "            data_list.append(data)\n",
        "        \n",
        "        model_output = model.predict(data_list, batch_size, gpu_numbers)\n",
        "        dataframe['COMET'] = model_output.scores\n",
        "\n",
        "        # Add COMET system_score to self.COMET_sytem_score variable \n",
        "        # so when we need COMET system_score, there won't be any need to recalculate it\n",
        "        self.COMET_sytem_score = model_output.system_score\n",
        "\n",
        "        return dataframe\n",
        "\n",
        "    def evaluating_from_dataframe(self, dataframe, save_path='/data/df_result_with_evaluation.csv'\n",
        "                                  , COMET_model_batch_size=8, COMET_model_gpu_numbers=1):\n",
        "        \"\"\"\n",
        "        Evaluating translations from privided csv file path.\n",
        "        Args\n",
        "            dataframe (:obj:`pandas dataframe'): Translation dataframe with agreed structure\n",
        "            save_path (:obj: 'str'): path for saving the result dataframe in csv format\n",
        "        Returns\n",
        "            dataframe (:obj: 'pandas dataframe'): The dataframe with 3 evaluation metrics columns (BLEU, chrf, COMET)\n",
        "        \"\"\"\n",
        "        dataframe = self.calculate_sentence_bleu(dataframe)\n",
        "        dataframe = self.calculate_sentence_chrf(dataframe)\n",
        "        dataframe = self.calculate_COMET(dataframe\n",
        "                                            , batch_size=COMET_model_batch_size, gpu_numbers=COMET_model_gpu_numbers)\n",
        "\n",
        "        dataframe.to_csv(save_path, sep=',')\n",
        "        return dataframe\n",
        "\n",
        "    def evaluating_from_file_path(self, prediction_file_path, sep=',', encoding='utf-8', save_path='/data/'\n",
        "                                  , COMET_model_batch_size=8, COMET_model_gpu_numbers=1):\n",
        "        \"\"\"\n",
        "        Evaluating translations from privided csv file path.\n",
        "        Args\n",
        "            prediction_file_path (:obj:`str'): CSV file path with agreed structure\n",
        "            sep (:obj: 'str'): seperator of csv file\n",
        "            encoding (:obj: 'str'): encoding of csv file\n",
        "            save_path (:obj: 'str'): path for saving the result dataframe in csv format\n",
        "        Returns\n",
        "            dataframe (:obj: 'pandas dataframe'): The dataframe with 3 evaluation metrics columns (BLEU, chrf, COMET)\n",
        "        \"\"\"\n",
        "\n",
        "        dataframe = pd.read_csv(prediction_file_path, sep=sep, encoding=encoding)\n",
        "        dataframe = self.calculate_sentence_bleu(dataframe)\n",
        "        dataframe = self.calculate_sentence_chrf(dataframe)\n",
        "        dataframe = self.calculate_COMET(dataframe\n",
        "                                             , batch_size=COMET_model_batch_size, gpu_numbers=COMET_model_gpu_numbers)\n",
        "\n",
        "        dataframe.to_csv(save_path, sep=',')\n",
        "        return dataframe\n",
        "\n",
        "    def calculate_corpus_bleu(self, dataframe):\n",
        "        \"\"\"\n",
        "        Calculating the corpus BLEU score over entire translations.\n",
        "        Args\n",
        "            dataframe (:obj:`pandas dataframe`):\n",
        "        Return\n",
        "            dictionary (:obj: `dict`): dictionary of BLEU2, BLEU3, and BLEU4 scores\n",
        "        \"\"\"\n",
        "        list_of_references = []\n",
        "        for sentence in dataframe['target'].values:\n",
        "            list_of_references.append([word_tokenize(str(sentence))])\n",
        "\n",
        "        hypotheses = []\n",
        "        for sentence in dataframe['translation'].values:\n",
        "            hypotheses.append(word_tokenize(str(sentence)))\n",
        "\n",
        "        weights = [\n",
        "            (1./2., 1./2.),\n",
        "            (1./3., 1./3., 1./3.),\n",
        "            (1./4., 1./4., 1./4., 1./4.)\n",
        "            ]\n",
        "        smoothie = SmoothingFunction().method4\n",
        "        bleu_corpus_scores = corpus_bleu(list_of_references, hypotheses, weights, smoothing_function=smoothie)\n",
        "        return {'BLEU2': bleu_corpus_scores[0], 'BLEU3': bleu_corpus_scores[1], 'BLEU4': bleu_corpus_scores[2]}\n",
        "\n",
        "    def calculate_mean_bleu(self, dataframe):\n",
        "        \"\"\"\n",
        "            Calculating the mean BLEU score over entire translations.\n",
        "        \"\"\"\n",
        "        mean_bleu = dataframe.loc[:, 'BLEU'].mean()\n",
        "        return mean_bleu\n",
        "\n",
        "    def calculate_corpus_chrf(self, dataframe):\n",
        "        \"\"\"\n",
        "        Calculating the corpus chrf score over entire translations.\n",
        "        \"\"\"\n",
        "        list_of_references = []\n",
        "        for sentence in dataframe['target'].values:\n",
        "            list_of_references.append([str(sentence)])\n",
        "\n",
        "        hypotheses = []\n",
        "        for sentence in dataframe['translation'].values:\n",
        "            hypotheses.append([str(sentence)])\n",
        "\n",
        "        return corpus_chrf(list_of_references, hypotheses)\n",
        "\n",
        "    def calculate_mean_chrf(self, dataframe):\n",
        "        \"\"\"\n",
        "        Calculating the mean chrf score over entire translations.\n",
        "        \"\"\"\n",
        "        mean_bleu = dataframe.loc[:, 'chrf'].mean()\n",
        "        return mean_bleu\n",
        "\n",
        "    def get_system_score_COMET(self):\n",
        "        if self.COMET_sytem_score == 0:\n",
        "            return 'COMET system score has not been computed yet. Call calculate_system_score_COMET() to compute it directly.'\n",
        "        else:\n",
        "            return self.COMET_sytem_score\n",
        "\n",
        "    def calculate_system_score_COMET(self, dataframe, batch_size=16, gpu_numbers=1):\n",
        "        \"\"\"\n",
        "        Calculate system_score (mean) COMET score over entire translations.\n",
        "        Args\n",
        "            df_prediction (:obj:`pandas dataframe'): Dataframe contains source text, reference text ,and translation text\n",
        "            model_name (:obj:`str`): Model name of COMET library from below link:\n",
        "            1. https://huggingface.co/Unbabel\n",
        "            The default value is 'Unbabel/wmt22-comet-da' which is built on top of XLM-R\n",
        "            and has been trained on direct assessments from WMT17 to WMT20 and provides scores ranging from 0 to 1\n",
        "            , where 1 represents a perfect translation.\n",
        "            batch_size (:obj: 'int'): batch_size\n",
        "            gpu_numbers (:obj: 'int'): Number of GPUs\n",
        "        Returns\n",
        "            system_score (:obj: 'float'): The mean COMET score over entire translations.\n",
        "        \"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_numbers = gpu_numbers\n",
        "        else:\n",
        "            gpu_numbers = 0\n",
        "\n",
        "        model = load_from_checkpoint(self.COMET_model_path)\n",
        "\n",
        "        data_list = []\n",
        "        for i, r in dataframe.iterrows():\n",
        "            data = {\n",
        "                'src': str(r['source']),\n",
        "                'mt': str(r['translation']),\n",
        "                'ref': str(r['target'])\n",
        "            }\n",
        "            data_list.append(data)\n",
        "\n",
        "        model_output = model.predict(data_list, batch_size=batch_size, gpus=gpu_numbers)\n",
        "        return model_output.system_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejWLGzHdMDqg"
      },
      "source": [
        "#  PEFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNfFPObIWX2Q"
      },
      "source": [
        "This is valid for sequence-to-sequence models, like:\n",
        "\n",
        "*   T5\n",
        "*   BLOOM\n",
        "*   mBART\n",
        "*   NLLB\n",
        "\n",
        "T5 (and variants) and BLOOM need a prefix before the source sentence, mbart and nllb do not need a prefix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQs4Wiq6WtGC",
        "outputId": "d025de20-0af6-4cee-bac9-2d7a4b057b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model chosen: google/flan-t5-small\n"
          ]
        }
      ],
      "source": [
        "if m == \"t5\":\n",
        "  model_name = \"google/flan-t5-small\"\n",
        "  #model_name = \"google/mt5-small\"\n",
        "  #model_name = \"google/flan-ul2\"\n",
        "  tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "elif m == \"bloom\":\n",
        "  model_name = \"bigscience/mt0-small\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# elif m == \"mbart\":\n",
        "#   model_name = \"facebook/mbart-large-50\"\n",
        "#   tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "#                                                   model_name, \n",
        "#                                                   src_lang=\"{}_XX\".format(src_lang), \n",
        "#                                                   tgt_lang=\"{}_XX\".format(trg_lang)\n",
        "#                                                   )\n",
        "# elif m == \"nllb\":\n",
        "#   model_name = \"facebook/nllb-200-distilled-600M\" # \"facebook/nllb-200-distilled-1.3B\"\n",
        "#   tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(\"Model chosen: {}\".format(model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxD5dVdv-kHL"
      },
      "outputs": [],
      "source": [
        "max_length = 256\n",
        "lr = 1e-4\n",
        "num_epochs = 1\n",
        "batch_size = 2\n",
        "lora_alpha = 32\n",
        "lora_dropout = 0.1\n",
        "lora_r = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfduTCjEFzoP",
        "outputId": "7fcb2863-7c02-4633-975b-c3a9e458e537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "AVAIL_GPUS = 0\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    AVAIL_GPUS = torch.cuda.device_count()\n",
        "    print(f'There are {AVAIL_GPUS} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "                                                                                                                                                                                                                                            \n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIu9FMv_V_4Y"
      },
      "source": [
        "## Flores \"Classic\" Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A34o7YVfS7d"
      },
      "outputs": [],
      "source": [
        "prefix = \"translate Italian to Spanish:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJXjENv8X4Tw"
      },
      "outputs": [],
      "source": [
        "src_lang =\"ita\"\n",
        "trg_lang = \"spa\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "p9naJKrvCaK2",
        "outputId": "8024d5f9-1fe7-4313-ee2e-6c6b33b4e20f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230328_071921-ny78al4k</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mt2magic/translated-challenge/runs/ny78al4k' target=\"_blank\">bigscience/mt0-small_peft_Flores_ita_spa</a></strong> to <a href='https://wandb.ai/mt2magic/translated-challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mt2magic/translated-challenge' target=\"_blank\">https://wandb.ai/mt2magic/translated-challenge</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mt2magic/translated-challenge/runs/ny78al4k' target=\"_blank\">https://wandb.ai/mt2magic/translated-challenge/runs/ny78al4k</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mt2magic/translated-challenge/runs/ny78al4k?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f0781421190>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(name=f\"{model_name}_{method}_Flores_{src_lang}_{trg_lang}\", project='translated-challenge', entity='mt2magic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYEsGHM_Hwvs"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0NMt4vya4Pu"
      },
      "outputs": [],
      "source": [
        "class FloresDataset(Dataset):\n",
        "  def __init__(self, src_file, trg_file, tokenizer, max_length=1024):\n",
        "\n",
        "    self.src_sentences = []\n",
        "    self.trg_sentences = []\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "    \n",
        "    with open(src_file, 'r') as f:\n",
        "      for line in f:\n",
        "        if m in [\"t5\", \"bloom\"]:\n",
        "          self.src_sentences.append(prefix + line.strip())\n",
        "        else:\n",
        "          self.src_sentences.append(line.strip())\n",
        "    \n",
        "    with open(trg_file, 'r') as f:\n",
        "      for line in f:\n",
        "        self.trg_sentences.append(line.strip())\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src_sentences)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    src_encoding = self.tokenizer(self.src_sentences[index], truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "    \n",
        "    trg_encoding = self.tokenizer(self.trg_sentences[index], truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "    \n",
        "    input_ids = src_encoding['input_ids'].squeeze()\n",
        "    attention_mask = src_encoding['attention_mask'].squeeze()\n",
        "    trg_input_ids = trg_encoding['input_ids'].squeeze()\n",
        "    \n",
        "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': trg_input_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG4GMiegbL0I",
        "outputId": "c650c40a-cda0-4454-9238-c50d899f9411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in the train set: 997\n",
            "Number of samples in the eval set: 1012\n"
          ]
        }
      ],
      "source": [
        "train_dataset = FloresDataset(\"/content/drive/MyDrive/Data/Flores/{}_Latn.dev\".format(src_lang), \"/content/drive/MyDrive/Data/Flores/{}_Latn.dev\".format(trg_lang), tokenizer)\n",
        "eval_dataset = FloresDataset(\"/content/drive/MyDrive/Data/Flores/{}_Latn.devtest\".format(src_lang), \"/content/drive/MyDrive/Data/Flores/{}_Latn.devtest\".format(trg_lang), tokenizer)\n",
        "print(\"Number of samples in the train set: {}\".format(len(train_dataset)))\n",
        "print(\"Number of samples in the eval set: {}\".format(len(eval_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-IFQZzvbmyb"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy0p4hM6wfWl"
      },
      "source": [
        "### Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "05a6fffde3904e52afcd21b7ee3c7e66",
            "d70bb59244c84124af9f8d336a279ec1",
            "08f15faf53034447bd78f1fc5d6145b3",
            "4750f829720f439c87dd03bf54221a98",
            "896282e7c00a4bdd8be9effd325ec7aa",
            "9bdd84f224874ec6915b9c5fa22d0f88",
            "5aa7f49bac3848bdbdd3ccf7fef4009f",
            "2c58f11f4b404873848931be2d9a8559",
            "2d118bd50f12433797e8c249a434f4e4",
            "62419bddc6224a01925a9485caaf6b03",
            "ff37143647104855a972fc78a56b4d13",
            "7d3ce224e71d43269e7e33264d5ac613",
            "b4b868d166374d11be0297579c56746e",
            "11bf302769654b67bc474dcce7561dbb",
            "a0a24aba5f554e6cb5c438efedb330aa",
            "1d5c3847bbef472693ca22b5a69a4790",
            "02b4de17a4cd4f43a8ce4d7ce73f0fd5",
            "451455f0a05942a59f7436ffcea3bcfb",
            "8b1fff8778964ab9af86cac0c10972d3",
            "472c58298b93427c8761815855e00c78",
            "5e406a571d3b43df91c4087bc132aac3",
            "fb3ef5254b7d4f328e1159216ac2f602"
          ]
        },
        "id": "aY5ErqnnJACT",
        "outputId": "1195d844-c5c2-4a2f-a6fe-e857f0e39e64"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05a6fffde3904e52afcd21b7ee3c7e66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/773 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d3ce224e71d43269e7e33264d5ac613",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=lora_r, lora_alpha=lora_alpha, lora_dropout=lora_dropout)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "#peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igl7az5EOHVN",
        "outputId": "7d1f9307-5461-4322-8044-ba0cde3a59d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 688128 || all params: 300864896 || trainable%: 0.2287166130541198\n"
          ]
        }
      ],
      "source": [
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud26txZSCqJB"
      },
      "outputs": [],
      "source": [
        "config = wandb.config\n",
        "config.model = model_name\n",
        "config.batch_size = batch_size\n",
        "config.learning_rate = lr\n",
        "config.max_length = max_length\n",
        "config.epochs = num_epochs\n",
        "config.lora_alpha = lora_alpha\n",
        "config.lora_dropout = lora_dropout\n",
        "config.lor_r = lora_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT_fENYm-qfB"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(peft_model.parameters(), lr=lr)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")\n",
        "config.optimizer = \"AdamW\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peyT1SyU-sEA"
      },
      "outputs": [],
      "source": [
        "# training and evaluation\n",
        "peft_model = peft_model.to(device)\n",
        "wandb.watch(peft_model, log=\"all\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    peft_model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = peft_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.detach().float()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    peft_model.eval()\n",
        "    eval_loss = 0\n",
        "    eval_preds = []\n",
        "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = peft_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        eval_loss += loss.detach().float()\n",
        "        eval_preds.extend(\n",
        "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
        "        )\n",
        "\n",
        "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
        "    eval_ppl = torch.exp(eval_epoch_loss)\n",
        "    train_epoch_loss = total_loss / len(train_dataloader)\n",
        "    train_ppl = torch.exp(train_epoch_loss)\n",
        "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")\n",
        "    wandb.log({'epoch': epoch + 1, 'train_loss': train_epoch_loss, 'eval_loss':eval_epoch_loss})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOsdfLQsVJM8"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feHYh_73mTCP"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, samples, target):\n",
        "  results = []\n",
        "  for i,m in enumerate(samples):\n",
        "    message = prefix + m\n",
        "    inputs = tokenizer.encode(message, truncation=False, max_length=1024, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(inputs=inputs)\n",
        "    results.append([m, target[i], tokenizer.decode(output[0])])\n",
        "\n",
        "  df = pd.DataFrame(results, columns=[\"source\",\"target\",\"translation\"])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fd9w0BVYsjw"
      },
      "outputs": [],
      "source": [
        "data_eng = load_dataset(\"gsarti/flores_101\",src_lang)\n",
        "data_fra = load_dataset(\"gsarti/flores_101\",trg_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80OS16cBqhBu"
      },
      "outputs": [],
      "source": [
        "samples = data_eng[\"devtest\"][\"sentence\"]#[:5]\n",
        "target = data_fra[\"devtest\"][\"sentence\"]#[:5]\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sptmvQERmjpg"
      },
      "outputs": [],
      "source": [
        "if method == \"peft\":\n",
        "  df = get_predictions(peft_model, samples, target)\n",
        "elif method == \"normal\":\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "  model = model.to(device)\n",
        "  df = get_predictions(model, samples, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wHlDondim5I"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwYMVYRcmjyX"
      },
      "outputs": [],
      "source": [
        "print(df.source[0], \"\\n\", df.translation[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs_ZFaCUDqC5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "eval = Evaluator()\n",
        "df_translation = eval.evaluating_from_dataframe(df, save_path=\"/content/data/\")\n",
        "#df_translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcQE34bWbhS1"
      },
      "outputs": [],
      "source": [
        "print(df_translation[\"source\"][1], \"\\n\", df_translation[\"target\"][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWD_DaVCVLKc"
      },
      "outputs": [],
      "source": [
        "corpus_bleu = eval.calculate_corpus_bleu(df_translation)\n",
        "mean_bleu = eval.calculate_mean_bleu(df_translation)\n",
        "corpus_chrf = eval.calculate_corpus_chrf(df_translation)\n",
        "mean_chrf = eval.calculate_mean_chrf(df_translation)\n",
        "mean_comet = eval.calculate_system_score_COMET(df_translation)\n",
        "print('*** *** ***')\n",
        "print(f'Corpus BLEU: {corpus_bleu}')\n",
        "print(f'Mean BLEU: {mean_bleu}')\n",
        "print('*** *** ***')\n",
        "print(f'Corpus chrf: {corpus_chrf}')\n",
        "print(f'Mean chrf: {mean_chrf}')\n",
        "print('*** *** ***')\n",
        "print(f'\\nMean COMET: {mean_comet}')\n",
        "print('*** *** ***')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXL8t1IMKZz5"
      },
      "outputs": [],
      "source": [
        "wandb.log({'corpus_bleu': corpus_bleu, 'mean_bleu': mean_bleu, 'corpus_chrf': corpus_chrf, 'mean_chrf': mean_chrf, 'mean_comet':mean_comet})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luvOUmZt1cTN"
      },
      "source": [
        "## Flores Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxM1bCn7ad-f"
      },
      "outputs": [],
      "source": [
        "src_lang =\"ita\"\n",
        "trg_lang = \"spa\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EFaS-w3aSMu"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/Data/Flores/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mjk7ZlOad-f"
      },
      "outputs": [],
      "source": [
        "prefix = \"translate Italian to Spanish:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "1cqHxHGxm0IN",
        "outputId": "38112f42-9292-4eef-cf94-a14f9b0a0aec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgianfree_romani\u001b[0m (\u001b[33mmt2magic\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20230330_160033-6pg81jg2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mt2magic/translated-challenge/runs/6pg81jg2' target=\"_blank\">google/flan-t5-small_peft_Translated_ita_spa</a></strong> to <a href='https://wandb.ai/mt2magic/translated-challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mt2magic/translated-challenge' target=\"_blank\">https://wandb.ai/mt2magic/translated-challenge</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mt2magic/translated-challenge/runs/6pg81jg2' target=\"_blank\">https://wandb.ai/mt2magic/translated-challenge/runs/6pg81jg2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb_logger = WandbLogger(name=f\"{model_name}_{method}_Translated_{src_lang}_{trg_lang}\", project='translated-challenge', entity='mt2magic', log_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djRdiEJ7TZjN"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUIw_HDy1k9Y"
      },
      "outputs": [],
      "source": [
        "class PEFTDataset(Dataset):\n",
        "    def __init__(self, input_id, attention, labels):\n",
        "        self.attention = attention\n",
        "        self.input_id = input_id\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "        attention = self.attention[idx]\n",
        "        label = self.labels[idx]\n",
        "        input_id = self.input_id[idx]\n",
        "        sample = {\"attention_mask\": attention,\n",
        "                  \"input_ids\": input_id, \"labels\": label}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8quVbBKv1f3P"
      },
      "outputs": [],
      "source": [
        "class FloresDataModule(LightningDataModule):\n",
        "  def __init__(self, src_lang:str, trg_lang:str, path:str, tokenizer, max_length:int=128, batch_size:int=32, prefix:str=\"Translate from Italian to Spanish:\"):\n",
        "    super().__init__()\n",
        "\n",
        "    self.src_lang = src_lang\n",
        "    self.trg_lang = trg_lang\n",
        "    self.path = path\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.max_length = max_length\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(tokenizer, use_fast=True)\n",
        "    self.prefix = prefix\n",
        "\n",
        "  def prepare_split(self, split:str=\"dev\"):\n",
        "    src_sentences = []\n",
        "    self.src_file = self.path + \"{}_Latn.{}\".format(self.src_lang, split)\n",
        "    with open(self.src_file, 'r') as f:\n",
        "      for line in f:\n",
        "        src_sentences.append(line.strip())\n",
        "    trg_sentences = []\n",
        "    self.trg_file = self.path + \"{}_Latn.{}\".format(self.trg_lang, split)\n",
        "    with open(self.trg_file, 'r') as f:\n",
        "      for line in f:\n",
        "        trg_sentences.append(line.strip())\n",
        "    \n",
        "    df = pd.DataFrame(list(zip(src_sentences, trg_sentences)), columns=['original', 'translation'])\n",
        "    return df\n",
        "\n",
        "  def setup(self, stage:str=None):\n",
        "    train_data, val_data = train_test_split(self.prepare_split(\"dev\"), test_size=0.2, random_state=42)\n",
        "    test_data = self.prepare_split(\"devtest\")\n",
        "\n",
        "    self.X_train_enc, self.X_train_attention, self.Y_train_enc = self.preprocess_data(train_data)\n",
        "    self.X_val_enc, self.X_val_attention, self.Y_val_enc = self.preprocess_data(val_data)\n",
        "    self.X_test_enc, self.X_test_attention, self.Y_test_enc = self.preprocess_data(test_data)\n",
        "    \n",
        "  # def setup(self, stage:str=None):\n",
        "  #   train_data = pd.read_csv(self.train_file)\n",
        "  #   val_data = pd.read_csv(self.val_file)\n",
        "  #   test_data = pd.read_csv(self.test_file)\n",
        "    \n",
        "  #   self.X_train_enc, self.X_train_attention, self.Y_train_enc = self.preprocess_data(train_data)\n",
        "  #   self.X_val_enc, self.X_val_attention, self.Y_val_enc = self.preprocess_data(val_data)\n",
        "  #   self.X_test_enc, self.X_test_attention, self.Y_test_enc = self.preprocess_data(test_data)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = PEFTDataset(self.X_train_enc,self.X_train_attention, self.Y_train_enc)\n",
        "    return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = PEFTDataset(self.X_val_enc,self.X_val_attention, self.Y_val_enc)\n",
        "    return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    test_dataset = PEFTDataset(self.X_test_enc, self.X_test_attention, self.Y_test_enc)\n",
        "    return DataLoader(test_dataset, batch_size=self.batch_size)\n",
        "\n",
        "  def preprocess_data(self, data:pd.DataFrame):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    trg_input_ids = []\n",
        "    #print(data)\n",
        "    for index, row in data.iterrows():\n",
        "      src_encoding = self.tokenizer.batch_encode_plus(\n",
        "            [self.prefix+row[\"original\"]], max_length=self.max_length, pad_to_max_length=True, truncation=True\n",
        "        )\n",
        "      trg_encoding = self.tokenizer.batch_encode_plus(\n",
        "            [row[\"translation\"]], max_length=self.max_length, pad_to_max_length=True, truncation=True\n",
        "        )\n",
        "      \n",
        "      input_ids.append(src_encoding.get('input_ids')[0])\n",
        "      attention_masks.append(src_encoding.get('attention_mask')[0])\n",
        "      trg_input_ids.append(trg_encoding.get('input_ids')[0])\n",
        "    \n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "    trg_input_ids = torch.tensor(trg_input_ids)\n",
        "    \n",
        "    return input_ids, attention_masks, trg_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Huu-VMO_1qxZ"
      },
      "outputs": [],
      "source": [
        "seed_everything(42)\n",
        "dm = FloresDataModule(src_lang,  \n",
        "                      trg_lang,\n",
        "                      data_path,\n",
        "                      tokenizer=model_name, \n",
        "                      batch_size=batch_size,\n",
        "                      max_length=max_length, \n",
        "                      prefix=prefix\n",
        "                      )\n",
        "dm.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehydQfnZd0UM"
      },
      "outputs": [],
      "source": [
        "# t = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "# it = iter(dm.train_dataloader())\n",
        "# for i in range(15):\n",
        "#   ex = next(it)\n",
        "#   r = t.decode(ex[\"input_ids\"][0], skip_special_tokens =True)\n",
        "#   print(r)\n",
        "#   r = t.decode(ex[\"labels\"][0], skip_special_tokens =True)\n",
        "#   print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8DOVJkKTc-v"
      },
      "source": [
        "### Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnP5EfTk17yP"
      },
      "outputs": [],
      "source": [
        "class PEFTModel(LightningModule):\n",
        "  def __init__(self, model_name:str, lora_r:float, lora_alpha:float, lora_dropout:float, device:str, lr=2e-5):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, \n",
        "                                  inference_mode=False, \n",
        "                                  target_modules=[\"q\", \"v\"], \n",
        "                                  r=lora_r, \n",
        "                                  lora_alpha=lora_alpha, \n",
        "                                  lora_dropout=lora_dropout\n",
        "                                  )\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)#, load_in_8bit=True, device_map='auto')\n",
        "    #model = prepare_model_for_int8_training(model)\n",
        "    self.peft_model = get_peft_model(model, self.peft_config).to(device)\n",
        "    self.lr = lr\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "  def forward(self, **inputs):\n",
        "    return self.peft_model(**inputs)\n",
        "\n",
        "  def predict_step(self, batch, batch_idx:int, dataloader_idx:int=0):\n",
        "    return self(**batch)\n",
        "\n",
        "  def training_step(self, batch, batch_idx:int):\n",
        "    outputs = self(**batch)\n",
        "    loss = outputs.loss\n",
        "    self.log('train_loss', loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx:int):\n",
        "    outputs = self(**batch)\n",
        "    loss = outputs.loss\n",
        "    self.log('val_loss', loss)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfxpGiSc1_CC"
      },
      "outputs": [],
      "source": [
        "model = PEFTModel(model_name, lora_r, lora_alpha, lora_dropout, device=device, lr=lr)\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=num_epochs,\n",
        "    gpus=1,\n",
        "    logger= wandb_logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0178e7cc238140d38d2b2eddbed5eff6",
            "1989c8d6438347acbe036953572c6130",
            "2b809101256e427dbada182f4f690f25",
            "4e505bbf60a34d16a34157f578e7ca1a",
            "bde47a18799141aca273a55d061b7b9c",
            "636d8283386644d2bcb53cb9666b9168",
            "366de25a7bd64e20ae5174717d3ac6df",
            "ba41526d469d4dff97fc884e73d5bab1",
            "f2f325517c764a8eb5d42bfd12966e6a",
            "cfe806258c04465aa81ad59db0f57e04",
            "0463c701c43b49ffa82855d24964491f",
            "e4336e66b9c44ca8949bdfaca94eff49",
            "7547191bb3f14cd8ad48f7f82a6797b4",
            "54f243efa180428b88a1d39af5b3bd28",
            "25d42f821cb74d8c8c20f9a0fd95fb3f",
            "84155f8f52cc40f896e508db4d874cbe",
            "06fea4ec743f400e9ed458dcac06a99b",
            "299ddd86d8984009a2172871b3a01eb0",
            "4444f7b1ed2d4255a57080c0c0be7654",
            "0b57ee07013341e7bf33a8df687001d1",
            "698bad68e561466d8bb747a3ef6c6968",
            "f81abc4dd873499fb1bacc1d8238e6c4",
            "bab2364df28c4266a6621a5fc36cf0e0",
            "1db5629c49834777a3c4b0d99806549c",
            "c58626b99aa545288ac21c61b7a5232d",
            "40c143b548d0457791390d84791a581d",
            "f0840fbba5d3465890730d085639ee09",
            "02782f693f024d8ea6e0701138bf9255",
            "26e70b307dd44e76a1185f007446c01c",
            "eecf94b1db344d81b819b9e040cb613f",
            "79fb9219ef0f4275a9a52dd394457211",
            "c909d5ec025041e2b599f1f54839eff4",
            "ff60191c0fc440379bbbc39ea46e819a"
          ]
        },
        "id": "h-mfw1EF2C3l",
        "outputId": "dfe3976c-602c-4357-bc1f-396d7de5a16d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0178e7cc238140d38d2b2eddbed5eff6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4336e66b9c44ca8949bdfaca94eff49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bab2364df28c4266a6621a5fc36cf0e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.fit(model, datamodule=dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZPz_ItuTfdk"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTTuW1EioRdu"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, df_samples:pd.DataFrame=None, samples_path:str=None):\n",
        "  if df_samples is not None:\n",
        "    data = df_samples\n",
        "  else:\n",
        "    data = pd.read_csv(samples_path)\n",
        "  results = []\n",
        "  for i,s in tqdm(data.iterrows(), total=data.shape[0]):\n",
        "    message = prefix + s[\"original\"]\n",
        "    inputs = tokenizer.encode(message, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "    output = model.generate(inputs=inputs, max_length=1024)\n",
        "    results.append([s[\"original\"], s[\"translation\"], tokenizer.decode(output[0], skip_special_tokens =True)])\n",
        "\n",
        "  df = pd.DataFrame(results, columns=[\"source\",\"target\",\"translation\"])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "R7JnVPJSAeaN",
        "outputId": "9f0712e4-e4c7-445f-9123-913b2803d996"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-60907b73-f90f-40bb-8158-b294f06525a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Abbiamo topi di quattro mesi che prima erano ...</td>\n",
              "      <td>«Actualmente, tenemos ratones de cuatro meses ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lo studio è ancora in fase iniziale, come dich...</td>\n",
              "      <td>La investigación todavía se ubica en su etapa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Come altri esperti, è scettico circa la possib...</td>\n",
              "      <td>Al igual que otros especialistas, es escéptico...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La segretaria permanente del Comitato per il N...</td>\n",
              "      <td>El lunes, Sara Danius, secretaria permanente d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Danius ha dischiarato: \"Ora come ora non stiam...</td>\n",
              "      <td>Danius declaró: «Actualmente no estamos hacien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>Dal momento che i territori sono scarsamente p...</td>\n",
              "      <td>Gracias a la escasa población que reside en di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>In Giappone, la cultura del lavoro è più gerar...</td>\n",
              "      <td>En Japón, la cultura laboral tiene una estruct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>L'abbigliamento da ufficio è costituito normal...</td>\n",
              "      <td>La vestimenta típica del ámbito de los negocio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>È di importanza cruciale l'armonia del luogo d...</td>\n",
              "      <td>La armonía en el lugar de trabajo es fundament...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>I lavoratori devono spesso ricevere il benesta...</td>\n",
              "      <td>Con frecuencia, los trabajadores deben contar ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1012 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60907b73-f90f-40bb-8158-b294f06525a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60907b73-f90f-40bb-8158-b294f06525a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60907b73-f90f-40bb-8158-b294f06525a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               original  \\\n",
              "0     \"Abbiamo topi di quattro mesi che prima erano ...   \n",
              "1     Lo studio è ancora in fase iniziale, come dich...   \n",
              "2     Come altri esperti, è scettico circa la possib...   \n",
              "3     La segretaria permanente del Comitato per il N...   \n",
              "4     Danius ha dischiarato: \"Ora come ora non stiam...   \n",
              "...                                                 ...   \n",
              "1007  Dal momento che i territori sono scarsamente p...   \n",
              "1008  In Giappone, la cultura del lavoro è più gerar...   \n",
              "1009  L'abbigliamento da ufficio è costituito normal...   \n",
              "1010  È di importanza cruciale l'armonia del luogo d...   \n",
              "1011  I lavoratori devono spesso ricevere il benesta...   \n",
              "\n",
              "                                            translation  \n",
              "0     «Actualmente, tenemos ratones de cuatro meses ...  \n",
              "1     La investigación todavía se ubica en su etapa ...  \n",
              "2     Al igual que otros especialistas, es escéptico...  \n",
              "3     El lunes, Sara Danius, secretaria permanente d...  \n",
              "4     Danius declaró: «Actualmente no estamos hacien...  \n",
              "...                                                 ...  \n",
              "1007  Gracias a la escasa población que reside en di...  \n",
              "1008  En Japón, la cultura laboral tiene una estruct...  \n",
              "1009  La vestimenta típica del ámbito de los negocio...  \n",
              "1010  La armonía en el lugar de trabajo es fundament...  \n",
              "1011  Con frecuencia, los trabajadores deben contar ...  \n",
              "\n",
              "[1012 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_samples = dm.prepare_split(\"devtest\")\n",
        "df_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y519oAPFoRdu",
        "outputId": "cb7453fb-2756-4156-a393-3f58bce50ba0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 626/1012 [08:24<04:05,  1.57it/s]"
          ]
        }
      ],
      "source": [
        "if method == \"peft\":\n",
        "  df = get_predictions(model.peft_model.to(device), df_samples=df_samples)\n",
        "elif method == \"normal\":\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "  model = model.to(device)\n",
        "  df = get_predictions(model, df_samples=df_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfsmqK1coRdu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "eval = Evaluator()\n",
        "df_translation = eval.evaluating_from_dataframe(df, save_path=\"/content/data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVN2IS4-oRdu"
      },
      "outputs": [],
      "source": [
        "print(df_translation[\"source\"][4], \"\\n\", df_translation[\"translation\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrKCKbmnoRdv"
      },
      "outputs": [],
      "source": [
        "corpus_bleu = eval.calculate_corpus_bleu(df_translation)\n",
        "mean_bleu = eval.calculate_mean_bleu(df_translation)\n",
        "corpus_chrf = eval.calculate_corpus_chrf(df_translation)\n",
        "mean_chrf = eval.calculate_mean_chrf(df_translation)\n",
        "mean_comet = eval.calculate_system_score_COMET(df_translation)\n",
        "print('*** *** ***')\n",
        "print(f'Corpus BLEU: {corpus_bleu}')\n",
        "print(f'Mean BLEU: {mean_bleu}')\n",
        "print('*** *** ***')\n",
        "print(f'Corpus chrf: {corpus_chrf}')\n",
        "print(f'Mean chrf: {mean_chrf}')\n",
        "print('*** *** ***')\n",
        "print(f'\\nMean COMET: {mean_comet}')\n",
        "print('*** *** ***')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_TESJ6QoRdv"
      },
      "outputs": [],
      "source": [
        "wandb_logger.experiment.config[\"corpus_bleu\"] = corpus_bleu\n",
        "wandb_logger.experiment.config[\"mean_bleu\"] = mean_bleu\n",
        "wandb_logger.experiment.config[\"corpus_chrf\"] = corpus_chrf\n",
        "wandb_logger.experiment.config[\"mean_chrf\"] = mean_chrf\n",
        "wandb_logger.experiment.config[\"mean_comet\"] = mean_comet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taBMOeMjCTTP"
      },
      "source": [
        "## Translated Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSo9opjGI9bY"
      },
      "outputs": [],
      "source": [
        "src_lang =\"ita\"\n",
        "trg_lang = \"eng\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aW0as1CmXEs"
      },
      "outputs": [],
      "source": [
        "prefix = \"translate Italian to English:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEqJtwHkmObb"
      },
      "outputs": [],
      "source": [
        "data_translated=\"/content/drive/MyDrive/Data/Translated/it-en-cleaned.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRwhMF5ScJl5"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/Data/Translated/split_data/train_it-en-translated.csv\"\n",
        "val_path = \"/content/drive/MyDrive/Data/Translated/split_data/val_it-en-translated.csv\"\n",
        "test_path = \"/content/drive/MyDrive/Data/Translated/split_data/test_it-en-translated.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "TDkhDF1FvZoZ",
        "outputId": "2d6a9769-19b4-4e35-a7c6-4acf3f08d97b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgianfree_romani\u001b[0m (\u001b[33mmt2magic\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20230329_082017-0q8fh6sm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mt2magic/translated-challenge/runs/0q8fh6sm' target=\"_blank\">google/flan-t5-small_peft_Translated_ita_eng</a></strong> to <a href='https://wandb.ai/mt2magic/translated-challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mt2magic/translated-challenge' target=\"_blank\">https://wandb.ai/mt2magic/translated-challenge</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mt2magic/translated-challenge/runs/0q8fh6sm' target=\"_blank\">https://wandb.ai/mt2magic/translated-challenge/runs/0q8fh6sm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb_logger = WandbLogger(name=f\"{model_name}_{method}_Translated_{src_lang}_{trg_lang}\", project='translated-challenge', entity='mt2magic', log_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSBUB8HIDueQ"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaW0u6XYXVtS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Split data stored in data_path in three splits\n",
        "test_size: how many rows will be used for test split, \n",
        "val_size: percentage of train data that will be used for validation\n",
        "random_state: set the random seed \n",
        "folder_csv_path: where the splits will be saved and stored\n",
        "\"\"\"\n",
        "import re\n",
        "def split_data(data_path, test_size=1000, val_size=0.2, random_state=42, folder_csv_path=\"/content/drive/MyDrive/Data/Translated/split_data/\"):\n",
        "  data = pd.read_csv(data_path)\n",
        "  filename = os.path.basename(data_path)\n",
        "  languages = re.findall(\"[A-Za-z]{2}-[A-Za-z]{2}-\", filename)[0]\n",
        "  train_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
        "  train_data, val_data = train_test_split(train_data, test_size=val_size, random_state=random_state)\n",
        "  train_path = folder_csv_path + f\"train_{languages}translated.csv\"\n",
        "  train_data.to_csv(train_path)\n",
        "  test_path = folder_csv_path + f\"test_{languages}translated.csv\"\n",
        "  test_data.to_csv(test_path)\n",
        "  val_path = folder_csv_path + f\"val_{languages}translated.csv\"\n",
        "  val_data.to_csv(val_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyLOVMtCXErz"
      },
      "outputs": [],
      "source": [
        "#split_data(data_translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIDlEuHTiwsX"
      },
      "outputs": [],
      "source": [
        "class PEFTDataset(Dataset):\n",
        "    def __init__(self, input_id, attention, labels):\n",
        "        self.attention = attention\n",
        "        self.input_id = input_id\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "        attention = self.attention[idx]\n",
        "        label = self.labels[idx]\n",
        "        input_id = self.input_id[idx]\n",
        "        sample = {\"attention_mask\": attention,\n",
        "                  \"input_ids\": input_id, \"labels\": label}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TZXvZzJbhBE"
      },
      "outputs": [],
      "source": [
        "class TranslatedDataModule(LightningDataModule):\n",
        "  def __init__(self, train_file:str, test_file:str, val_file:str, tokenizer, max_length:int=128, batch_size:int=32, prefix:str=\"Translate from Italian to Spanish\"):\n",
        "    super().__init__()\n",
        "\n",
        "    self.train_file = train_file\n",
        "    self.test_file = test_file\n",
        "    self.val_file = val_file\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.max_length = max_length\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(tokenizer, use_fast=True)\n",
        "    self.prefix = prefix\n",
        "\n",
        "  def setup(self, stage:str=None):\n",
        "    train_data = pd.read_csv(self.train_file)\n",
        "    val_data = pd.read_csv(self.val_file)\n",
        "    test_data = pd.read_csv(self.test_file)\n",
        "    \n",
        "    self.X_train_enc, self.X_train_attention, self.Y_train_enc = self.preprocess_data(train_data)\n",
        "    self.X_val_enc, self.X_val_attention, self.Y_val_enc = self.preprocess_data(val_data)\n",
        "    self.X_test_enc, self.X_test_attention, self.Y_test_enc = self.preprocess_data(test_data)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = PEFTDataset(self.X_train_enc,self.X_train_attention, self.Y_train_enc)\n",
        "    return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = PEFTDataset(self.X_val_enc,self.X_val_attention, self.Y_val_enc)\n",
        "    return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    test_dataset = PEFTDataset(self.X_test_enc, self.X_test_attention, self.Y_test_enc)\n",
        "    return DataLoader(test_dataset, batch_size=self.batch_size)\n",
        "\n",
        "  def preprocess_data(self, data:pd.DataFrame):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    trg_input_ids = []\n",
        "    for index, row in data.iterrows():\n",
        "      src_encoding = self.tokenizer.batch_encode_plus(\n",
        "            [self.prefix+row[\"original\"]], max_length=self.max_length, pad_to_max_length=True, truncation=True\n",
        "        )\n",
        "      trg_encoding = self.tokenizer.batch_encode_plus(\n",
        "            [row[\"translation\"]], max_length=self.max_length, pad_to_max_length=True, truncation=True\n",
        "        )\n",
        "      \n",
        "      input_ids.append(src_encoding.get('input_ids'))\n",
        "      attention_masks.append(src_encoding.get('attention_mask'))\n",
        "      trg_input_ids.append(trg_encoding.get('input_ids'))\n",
        "    \n",
        "    input_ids = torch.tensor(input_ids)[0]\n",
        "    attention_masks = torch.tensor(attention_masks)[0]\n",
        "    trg_input_ids = torch.tensor(trg_input_ids)[0]\n",
        "    \n",
        "    return input_ids, attention_masks, trg_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5-09M4yl-rx"
      },
      "outputs": [],
      "source": [
        "seed_everything(42)\n",
        "dm = TranslatedDataModule(train_path, \n",
        "                          val_path, \n",
        "                          test_path,\n",
        "                          tokenizer=model_name, \n",
        "                          batch_size=batch_size,\n",
        "                          max_length=max_length, \n",
        "                          prefix=prefix\n",
        "                          )\n",
        "dm.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaLiN-qtqlde"
      },
      "outputs": [],
      "source": [
        "# ex = next(iter(dm.train_dataloader()))\n",
        "# print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aLCNT1aDxsJ"
      },
      "source": [
        "### Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o87UZZVxrcgP"
      },
      "outputs": [],
      "source": [
        "class PEFTModel(LightningModule):\n",
        "  def __init__(self, model_name:str, lora_r:float, lora_alpha:float, lora_dropout:float, device:str, lr=2e-5):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, \n",
        "                                  inference_mode=False, \n",
        "                                  target_modules=[\"q\", \"v\"], \n",
        "                                  r=lora_r, \n",
        "                                  lora_alpha=lora_alpha, \n",
        "                                  lora_dropout=lora_dropout\n",
        "                                  )\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)#, load_in_8bit=True, device_map='auto')\n",
        "    #model = prepare_model_for_int8_training(model)\n",
        "    self.peft_model = get_peft_model(model, self.peft_config).to(device)\n",
        "    self.lr = lr\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "  def forward(self, **inputs):\n",
        "    return self.peft_model(**inputs)\n",
        "\n",
        "  def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "    return self(**batch)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    outputs = self(**batch)\n",
        "    loss = outputs.loss\n",
        "    self.log('train_loss', loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    outputs = self(**batch)\n",
        "    loss = outputs.loss\n",
        "    self.log('val_loss', loss)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM3-uOxF3qgM"
      },
      "outputs": [],
      "source": [
        "wandb_logger.experiment.config[\"max_length\"] = max_length\n",
        "wandb_logger.experiment.config[\"lr\"] = lr\n",
        "wandb_logger.experiment.config[\"num_epochs\"] = num_epochs\n",
        "wandb_logger.experiment.config[\"batch_size\"] = batch_size\n",
        "wandb_logger.experiment.config[\"lora_alpha\"] = lora_alpha\n",
        "wandb_logger.experiment.config[\"lora_dropout\"] = lora_dropout\n",
        "wandb_logger.experiment.config[\"lora_r\"] = lora_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUoKQYbiBeJg"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "model = PEFTModel(model_name, lora_r, lora_alpha, lora_dropout, device=device, lr=lr)\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=num_epochs,\n",
        "    gpus=1,\n",
        "    logger= wandb_logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "624609fe5b7b4821b5652c35801dece3",
            "ad81205bb33a423593bdceb2e6302bae",
            "fe7dd9a7998d4d10a0fdb97c5a7a3b46",
            "c44a7b085b1f48f38c23c890754aff66",
            "7514a90c07d84eb4bc344047de47242a",
            "c4ec1e7bb02c4a51ad9034095fc8525d",
            "ecfaa7608bf34f4cacb5bb00aa7bff79"
          ]
        },
        "id": "7LF7sQKbB_4g",
        "outputId": "e4297841-de9a-4f9f-8691-f29a34147e24"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "624609fe5b7b4821b5652c35801dece3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad81205bb33a423593bdceb2e6302bae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe7dd9a7998d4d10a0fdb97c5a7a3b46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c44a7b085b1f48f38c23c890754aff66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7514a90c07d84eb4bc344047de47242a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4ec1e7bb02c4a51ad9034095fc8525d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecfaa7608bf34f4cacb5bb00aa7bff79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.fit(model, datamodule=dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS4_rTrqCpk3"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJdAUQ0uSvSG"
      },
      "outputs": [],
      "source": [
        "# # Faster version\n",
        "# def get_predictions(model, samples_path, dm):\n",
        "  \n",
        "#   translations = []\n",
        "#   for inputs in dm:\n",
        "#     outputs = model.generate(**inputs, max_length=1024)\n",
        "#     translations += [tokenizer.decode(outputs, skip_special_tokens=True) for output in outputs]\n",
        "#   results = pd.read_csv(samples_path)\n",
        "#   results[\"translation\"] = translations\n",
        "#   return results[[\"source\",\"target\",\"translation\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dkDniFtV5h_"
      },
      "outputs": [],
      "source": [
        "# sample = \"Il Data Protection Officer (DPO) è una figura introdotta dal Regolamento sulla protezione dei dati (Regolamento UE 2016/679), il quale deve osservare, valutare e organizzare la gestione del trattamento dei dati personali all’interno dell’azienda, affinché essi siano trattati nel rispetto delle normative sulla privacy a livello nazionale ed europeo.\"\n",
        "# sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjGAgx4eU43C"
      },
      "outputs": [],
      "source": [
        "# message = prefix + sample\n",
        "# inputs = tokenizer.encode(message, return_tensors=\"pt\", padding=True)#.to(\"cuda\")\n",
        "# output = model.peft_model.generate(inputs=inputs, max_length=512)\n",
        "# r = tokenizer.decode(output[0], skip_special_tokens =True)\n",
        "# r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHQBwffvVwiY"
      },
      "outputs": [],
      "source": [
        "model_name = \"google/flan-t5-large\"\n",
        "model2 = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model2 = model2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWzqdrdDUdX9"
      },
      "outputs": [],
      "source": [
        "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NaGJbw4VpHx"
      },
      "outputs": [],
      "source": [
        "# prefix = \"translate Italian to Spanish:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "tJ_5JGgKTOqa",
        "outputId": "f67154fe-9054-4faf-d55a-5cc2d2bb86bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'model2'</span> is not defined\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'model2'\u001b[0m is not defined\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "message = prefix + \"Un aereo americano in difficoltà si schianta sopra il comune.\"\n",
        "inputs = tokenizer.encode(message, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "output = model2.generate(inputs=inputs, max_length=512)\n",
        "r = tokenizer.decode(output[0], skip_special_tokens =False)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g2xHWRKEAXx"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, samples_path:str):\n",
        "  data = pd.read_csv(samples_path)\n",
        "  results = []\n",
        "  for i,s in tqdm(data.iterrows(), total=data.shape[0]):\n",
        "    message = prefix + s[\"original\"]\n",
        "    inputs = tokenizer.encode(message, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "    output = model.generate(inputs=inputs, max_length=1024)\n",
        "    results.append([s[\"original\"], s[\"translation\"], tokenizer.decode(output[0], skip_special_tokens =True)])\n",
        "\n",
        "  df = pd.DataFrame(results, columns=[\"source\",\"target\",\"translation\"])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrrnXccThjik"
      },
      "outputs": [],
      "source": [
        "method=\"normal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYD4Z5ja29XZ",
        "outputId": "a642106d-0f1b-457e-8cf8-f765e75d7e2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [16:34<00:00,  1.01it/s]\n"
          ]
        }
      ],
      "source": [
        "if method == \"peft\":\n",
        "  df = get_predictions(model.peft_model.to(device), test_path)#, dm.test_dataloader)\n",
        "elif method == \"normal\":\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "  model = model.to(device)\n",
        "  df = get_predictions(model, test_path)#, dm.test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjFAj0hyCrlo"
      },
      "outputs": [],
      "source": [
        "# df = get_predictions(model.peft_model, test_path, dm.test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T0LPjh3D62W"
      },
      "outputs": [],
      "source": [
        "eval = Evaluator()\n",
        "df_translation = eval.evaluating_from_dataframe(df, save_path=\"/content/data/\")\n",
        "df_translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoMEIMsKw7uA",
        "outputId": "8c21e986-04c5-49c8-b505-a23be5bae0e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Un aereo americano in difficoltà si schianta sopra il comune.  \n",
            " A American scientist in the field is a common scientist.\n"
          ]
        }
      ],
      "source": [
        "print(df_translation[\"source\"][4], \"\\n\", df_translation[\"translation\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuBXlkSWD62W"
      },
      "outputs": [],
      "source": [
        "corpus_bleu = eval.calculate_corpus_bleu(df_translation)\n",
        "mean_bleu = eval.calculate_mean_bleu(df_translation)\n",
        "corpus_chrf = eval.calculate_corpus_chrf(df_translation)\n",
        "mean_chrf = eval.calculate_mean_chrf(df_translation)\n",
        "mean_comet = eval.calculate_system_score_COMET(df_translation)\n",
        "print('*** *** ***')\n",
        "print(f'Corpus BLEU: {corpus_bleu}')\n",
        "print(f'Mean BLEU: {mean_bleu}')\n",
        "print('*** *** ***')\n",
        "print(f'Corpus chrf: {corpus_chrf}')\n",
        "print(f'Mean chrf: {mean_chrf}')\n",
        "print('*** *** ***')\n",
        "print(f'\\nMean COMET: {mean_comet}')\n",
        "print('*** *** ***')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdeCxTC3VvXK"
      },
      "outputs": [],
      "source": [
        "wandb_logger.experiment.config[\"corpus_bleu\"] = corpus_bleu\n",
        "wandb_logger.experiment.config[\"mean_bleu\"] = mean_bleu\n",
        "wandb_logger.experiment.config[\"corpus_chrf\"] = corpus_chrf\n",
        "wandb_logger.experiment.config[\"mean_chrf\"] = mean_chrf\n",
        "wandb_logger.experiment.config[\"mean_comet\"] = mean_comet"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ayVsaD_iFRcR",
        "YIu9FMv_V_4Y",
        "bYEsGHM_Hwvs"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0178e7cc238140d38d2b2eddbed5eff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1989c8d6438347acbe036953572c6130",
              "IPY_MODEL_2b809101256e427dbada182f4f690f25",
              "IPY_MODEL_4e505bbf60a34d16a34157f578e7ca1a"
            ],
            "layout": "IPY_MODEL_bde47a18799141aca273a55d061b7b9c"
          }
        },
        "02782f693f024d8ea6e0701138bf9255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02b4de17a4cd4f43a8ce4d7ce73f0fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0463c701c43b49ffa82855d24964491f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05a6fffde3904e52afcd21b7ee3c7e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d70bb59244c84124af9f8d336a279ec1",
              "IPY_MODEL_08f15faf53034447bd78f1fc5d6145b3",
              "IPY_MODEL_4750f829720f439c87dd03bf54221a98"
            ],
            "layout": "IPY_MODEL_896282e7c00a4bdd8be9effd325ec7aa"
          }
        },
        "06fea4ec743f400e9ed458dcac06a99b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f15faf53034447bd78f1fc5d6145b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c58f11f4b404873848931be2d9a8559",
            "max": 773,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d118bd50f12433797e8c249a434f4e4",
            "value": 773
          }
        },
        "0b57ee07013341e7bf33a8df687001d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11bf302769654b67bc474dcce7561dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b1fff8778964ab9af86cac0c10972d3",
            "max": 1200768069,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_472c58298b93427c8761815855e00c78",
            "value": 1200768069
          }
        },
        "1989c8d6438347acbe036953572c6130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_636d8283386644d2bcb53cb9666b9168",
            "placeholder": "​",
            "style": "IPY_MODEL_366de25a7bd64e20ae5174717d3ac6df",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "1d5c3847bbef472693ca22b5a69a4790": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db5629c49834777a3c4b0d99806549c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02782f693f024d8ea6e0701138bf9255",
            "placeholder": "​",
            "style": "IPY_MODEL_26e70b307dd44e76a1185f007446c01c",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "25d42f821cb74d8c8c20f9a0fd95fb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698bad68e561466d8bb747a3ef6c6968",
            "placeholder": "​",
            "style": "IPY_MODEL_f81abc4dd873499fb1bacc1d8238e6c4",
            "value": " 499/499 [00:45&lt;00:00, 10.87it/s, loss=5.18, v_num=1jg2]"
          }
        },
        "26e70b307dd44e76a1185f007446c01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "299ddd86d8984009a2172871b3a01eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b809101256e427dbada182f4f690f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba41526d469d4dff97fc884e73d5bab1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2f325517c764a8eb5d42bfd12966e6a",
            "value": 2
          }
        },
        "2c58f11f4b404873848931be2d9a8559": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d118bd50f12433797e8c249a434f4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "366de25a7bd64e20ae5174717d3ac6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40c143b548d0457791390d84791a581d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c909d5ec025041e2b599f1f54839eff4",
            "placeholder": "​",
            "style": "IPY_MODEL_ff60191c0fc440379bbbc39ea46e819a",
            "value": " 100/100 [00:04&lt;00:00, 21.96it/s]"
          }
        },
        "4444f7b1ed2d4255a57080c0c0be7654": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "451455f0a05942a59f7436ffcea3bcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "472c58298b93427c8761815855e00c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4750f829720f439c87dd03bf54221a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62419bddc6224a01925a9485caaf6b03",
            "placeholder": "​",
            "style": "IPY_MODEL_ff37143647104855a972fc78a56b4d13",
            "value": " 773/773 [00:00&lt;00:00, 24.9kB/s]"
          }
        },
        "4e505bbf60a34d16a34157f578e7ca1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe806258c04465aa81ad59db0f57e04",
            "placeholder": "​",
            "style": "IPY_MODEL_0463c701c43b49ffa82855d24964491f",
            "value": " 2/2 [00:00&lt;00:00,  2.72it/s]"
          }
        },
        "54f243efa180428b88a1d39af5b3bd28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4444f7b1ed2d4255a57080c0c0be7654",
            "max": 499,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b57ee07013341e7bf33a8df687001d1",
            "value": 499
          }
        },
        "5aa7f49bac3848bdbdd3ccf7fef4009f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e406a571d3b43df91c4087bc132aac3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62419bddc6224a01925a9485caaf6b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636d8283386644d2bcb53cb9666b9168": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698bad68e561466d8bb747a3ef6c6968": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7547191bb3f14cd8ad48f7f82a6797b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06fea4ec743f400e9ed458dcac06a99b",
            "placeholder": "​",
            "style": "IPY_MODEL_299ddd86d8984009a2172871b3a01eb0",
            "value": "Epoch 0: 100%"
          }
        },
        "79fb9219ef0f4275a9a52dd394457211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d3ce224e71d43269e7e33264d5ac613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4b868d166374d11be0297579c56746e",
              "IPY_MODEL_11bf302769654b67bc474dcce7561dbb",
              "IPY_MODEL_a0a24aba5f554e6cb5c438efedb330aa"
            ],
            "layout": "IPY_MODEL_1d5c3847bbef472693ca22b5a69a4790"
          }
        },
        "84155f8f52cc40f896e508db4d874cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "896282e7c00a4bdd8be9effd325ec7aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1fff8778964ab9af86cac0c10972d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bdd84f224874ec6915b9c5fa22d0f88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a24aba5f554e6cb5c438efedb330aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e406a571d3b43df91c4087bc132aac3",
            "placeholder": "​",
            "style": "IPY_MODEL_fb3ef5254b7d4f328e1159216ac2f602",
            "value": " 1.20G/1.20G [00:12&lt;00:00, 95.9MB/s]"
          }
        },
        "b4b868d166374d11be0297579c56746e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b4de17a4cd4f43a8ce4d7ce73f0fd5",
            "placeholder": "​",
            "style": "IPY_MODEL_451455f0a05942a59f7436ffcea3bcfb",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "ba41526d469d4dff97fc884e73d5bab1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab2364df28c4266a6621a5fc36cf0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1db5629c49834777a3c4b0d99806549c",
              "IPY_MODEL_c58626b99aa545288ac21c61b7a5232d",
              "IPY_MODEL_40c143b548d0457791390d84791a581d"
            ],
            "layout": "IPY_MODEL_f0840fbba5d3465890730d085639ee09"
          }
        },
        "bde47a18799141aca273a55d061b7b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c58626b99aa545288ac21c61b7a5232d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eecf94b1db344d81b819b9e040cb613f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79fb9219ef0f4275a9a52dd394457211",
            "value": 100
          }
        },
        "c909d5ec025041e2b599f1f54839eff4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe806258c04465aa81ad59db0f57e04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70bb59244c84124af9f8d336a279ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bdd84f224874ec6915b9c5fa22d0f88",
            "placeholder": "​",
            "style": "IPY_MODEL_5aa7f49bac3848bdbdd3ccf7fef4009f",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e4336e66b9c44ca8949bdfaca94eff49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7547191bb3f14cd8ad48f7f82a6797b4",
              "IPY_MODEL_54f243efa180428b88a1d39af5b3bd28",
              "IPY_MODEL_25d42f821cb74d8c8c20f9a0fd95fb3f"
            ],
            "layout": "IPY_MODEL_84155f8f52cc40f896e508db4d874cbe"
          }
        },
        "eecf94b1db344d81b819b9e040cb613f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0840fbba5d3465890730d085639ee09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "f2f325517c764a8eb5d42bfd12966e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f81abc4dd873499fb1bacc1d8238e6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb3ef5254b7d4f328e1159216ac2f602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff37143647104855a972fc78a56b4d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff60191c0fc440379bbbc39ea46e819a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
